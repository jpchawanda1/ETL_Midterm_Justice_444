{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ac5c1d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== raw_data.csv: .head() ===\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|    |   order_id | customer_name   | product   |   quantity |   unit_price | order_date   | region   |\n",
      "+====+============+=================+===========+============+==============+==============+==========+\n",
      "|  0 |          1 | Diana           | Tablet    |        nan |          500 | 2024-01-20   | South    |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  1 |          2 | Eve             | Laptop    |        nan |          nan | 2024-04-29   | North    |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  2 |          3 | Charlie         | Laptop    |          2 |          250 | 2024-01-08   | nan      |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  3 |          4 | Eve             | Laptop    |          2 |          750 | 2024-01-07   | West     |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  4 |          5 | Eve             | Tablet    |          3 |          nan | 2024-03-07   | South    |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "\n",
      "=== raw_data.csv: .info() ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100 entries, 0 to 99\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       100 non-null    int64  \n",
      " 1   customer_name  99 non-null     object \n",
      " 2   product        100 non-null    object \n",
      " 3   quantity       74 non-null     float64\n",
      " 4   unit_price     65 non-null     float64\n",
      " 5   order_date     99 non-null     object \n",
      " 6   region         75 non-null     object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 5.6+ KB\n",
      "\n",
      "=== incremental_data.csv: .head() ===\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|    |   order_id | customer_name   | product   |   quantity |   unit_price | order_date   | region   |\n",
      "+====+============+=================+===========+============+==============+==============+==========+\n",
      "|  0 |        101 | Alice           | Laptop    |        nan |          900 | 2024-05-09   | Central  |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  1 |        102 | nan             | Laptop    |          1 |          300 | 2024-05-07   | Central  |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  2 |        103 | nan             | Laptop    |          1 |          600 | 2024-05-04   | Central  |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  3 |        104 | nan             | Tablet    |        nan |          300 | 2024-05-26   | Central  |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "|  4 |        105 | Heidi           | Tablet    |          2 |          600 | 2024-05-21   | North    |\n",
      "+----+------------+-----------------+-----------+------------+--------------+--------------+----------+\n",
      "\n",
      "=== incremental_data.csv: .info() ===\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10 entries, 0 to 9\n",
      "Data columns (total 7 columns):\n",
      " #   Column         Non-Null Count  Dtype  \n",
      "---  ------         --------------  -----  \n",
      " 0   order_id       10 non-null     int64  \n",
      " 1   customer_name  4 non-null      object \n",
      " 2   product        10 non-null     object \n",
      " 3   quantity       6 non-null      float64\n",
      " 4   unit_price     10 non-null     float64\n",
      " 5   order_date     10 non-null     object \n",
      " 6   region         8 non-null      object \n",
      "dtypes: float64(2), int64(1), object(4)\n",
      "memory usage: 688.0+ bytes\n",
      "\n",
      "--- Observations ---\n",
      "\n",
      "Missing Values Summary\n",
      "+----------------------+---------------+------------------+\n",
      "| File                 | Column        |   Missing Values |\n",
      "+======================+===============+==================+\n",
      "| raw_data.csv         | order_id      |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | customer_name |                1 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | product       |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | quantity      |               26 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | unit_price    |               35 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | order_date    |                1 |\n",
      "+----------------------+---------------+------------------+\n",
      "| raw_data.csv         | region        |               25 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | order_id      |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | customer_name |                6 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | product       |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | quantity      |                4 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | unit_price    |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | order_date    |                0 |\n",
      "+----------------------+---------------+------------------+\n",
      "| incremental_data.csv | region        |                2 |\n",
      "+----------------------+---------------+------------------+\n",
      "\n",
      "Duplicate Rows Summary\n",
      "+----------------------+------------------+\n",
      "| File                 |   Duplicate Rows |\n",
      "+======================+==================+\n",
      "| raw_data.csv         |                1 |\n",
      "+----------------------+------------------+\n",
      "| incremental_data.csv |                0 |\n",
      "+----------------------+------------------+\n",
      "\n",
      "Columns in Each File\n",
      "+----------------------+---------------+\n",
      "| File                 | Column        |\n",
      "+======================+===============+\n",
      "| raw_data.csv         | order_id      |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | customer_name |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | product       |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | quantity      |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | unit_price    |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | order_date    |\n",
      "+----------------------+---------------+\n",
      "| raw_data.csv         | region        |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | order_id      |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | customer_name |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | product       |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | quantity      |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | unit_price    |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | order_date    |\n",
      "+----------------------+---------------+\n",
      "| incremental_data.csv | region        |\n",
      "+----------------------+---------------+\n",
      "\n",
      "Raw copies saved as data/raw_data_copy.csv and data/incremental_data_copy.csv\n"
     ]
    }
   ],
   "source": [
    "# --- ETL Extract Step ---\n",
    "# 1. Load and preview raw_data.csv and incremental_data.csv\n",
    "# 2. Display .head() and .info() for each, using tabulate for tables\n",
    "# 3. Add observations about the data, also as tables\n",
    "# 4. Save raw copies to data/ directory\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "# Load the raw data\n",
    "raw_df = pd.read_csv('data/raw_data.csv')\n",
    "incremental_df = pd.read_csv('data/incremental_data.csv')\n",
    "\n",
    "# Preview the first few rows of each DataFrame using tabulate (grid style)\n",
    "print(\"=== raw_data.csv: .head() ===\")\n",
    "print(tabulate(raw_df.head(), headers='keys', tablefmt='grid'))\n",
    "print(\"\\n=== raw_data.csv: .info() ===\")\n",
    "raw_df.info()\n",
    "\n",
    "print(\"\\n=== incremental_data.csv: .head() ===\")\n",
    "print(tabulate(incremental_df.head(), headers='keys', tablefmt='grid'))\n",
    "print(\"\\n=== incremental_data.csv: .info() ===\")\n",
    "incremental_df.info()\n",
    "\n",
    "# Observations as tables\n",
    "print(\"\\n--- Observations ---\")\n",
    "\n",
    "# Missing values as tables\n",
    "print(\"\\nMissing Values Summary\")\n",
    "missing_data = [\n",
    "    [\"File\", \"Column\", \"Missing Values\"]\n",
    "]\n",
    "for df, name in zip([raw_df, incremental_df], [\"raw_data.csv\", \"incremental_data.csv\"]):\n",
    "    for col, val in df.isnull().sum().items():\n",
    "        missing_data.append([name, col, val])\n",
    "print(tabulate(missing_data[1:], headers=missing_data[0], tablefmt='grid'))\n",
    "\n",
    "# Duplicate rows as tables\n",
    "print(\"\\nDuplicate Rows Summary\")\n",
    "dup_data = [\n",
    "    [\"File\", \"Duplicate Rows\"],\n",
    "    [\"raw_data.csv\", raw_df.duplicated().sum()],\n",
    "    [\"incremental_data.csv\", incremental_df.duplicated().sum()]\n",
    "]\n",
    "print(tabulate(dup_data[1:], headers=dup_data[0], tablefmt='grid'))\n",
    "\n",
    "# Columns as tables\n",
    "print(\"\\nColumns in Each File\")\n",
    "col_data = [\n",
    "    [\"File\", \"Column\"]\n",
    "]\n",
    "for df, name in zip([raw_df, incremental_df], [\"raw_data.csv\", \"incremental_data.csv\"]):\n",
    "    for col in df.columns:\n",
    "        col_data.append([name, col])\n",
    "print(tabulate(col_data[1:], headers=col_data[0], tablefmt='grid'))\n",
    "\n",
    "# Save raw copies (redundant if already in data/, but ensures a backup)\n",
    "raw_df.to_csv('data/raw_data_copy.csv', index=False)\n",
    "incremental_df.to_csv('data/incremental_data_copy.csv', index=False)\n",
    "print(\"\\nRaw copies saved as data/raw_data_copy.csv and data/incremental_data_copy.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
