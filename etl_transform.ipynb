{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcfd91f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transformed files saved to 'transformed/transformed_full.csv' and 'transformed/transformed_incremental.csv'\n",
      "\n",
      "=== Head of transformed_full.csv ===\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|    |   order_id | customer_name   | product   | product_category   |   quantity |   unit_price |   total_price | order_date   | region   |\n",
      "+====+============+=================+===========+====================+============+==============+===============+==============+==========+\n",
      "|  0 |          1 | Diana           | Tablet    | Electronics        |          2 |          500 |          1000 | 2024-01-20   | South    |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  1 |          2 | Eve             | Laptop    | Electronics        |          2 |          500 |          1000 | 2024-04-29   | North    |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  2 |          3 | Charlie         | Laptop    | Electronics        |          2 |          250 |           500 | 2024-01-08   | Unknown  |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  3 |          4 | Eve             | Laptop    | Electronics        |          2 |          750 |          1500 | 2024-01-07   | West     |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  4 |          5 | Eve             | Tablet    | Electronics        |          3 |          500 |          1500 | 2024-03-07   | South    |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "\n",
      "=== Head of transformed_incremental.csv ===\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|    |   order_id | customer_name   | product   | product_category   |   quantity |   unit_price |   total_price | order_date   | region   |\n",
      "+====+============+=================+===========+====================+============+==============+===============+==============+==========+\n",
      "|  0 |        101 | Alice           | Laptop    | Electronics        |          2 |          900 |          1800 | 2024-05-09   | Central  |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  1 |        102 | Unknown         | Laptop    | Electronics        |          1 |          300 |           300 | 2024-05-07   | Central  |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  2 |        103 | Unknown         | Laptop    | Electronics        |          1 |          600 |           600 | 2024-05-04   | Central  |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  3 |        104 | Unknown         | Tablet    | Electronics        |          2 |          300 |           600 | 2024-05-26   | Central  |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "|  4 |        105 | Heidi           | Tablet    | Electronics        |          2 |          600 |          1200 | 2024-05-21   | North    |\n",
      "+----+------------+-----------------+-----------+--------------------+------------+--------------+---------------+--------------+----------+\n",
      "\n",
      "=== Transformation Summary: transformed_full.csv ===\n",
      "+--------------------------------+----------------------+\n",
      "| File                           | transformed_full.csv |\n",
      "+--------------------------------+----------------------+\n",
      "| Rows                           | 99                   |\n",
      "+--------------------------------+----------------------+\n",
      "| Duplicate Rows                 | 0                    |\n",
      "+--------------------------------+----------------------+\n",
      "| Any Missing Values             | False                |\n",
      "+--------------------------------+----------------------+\n",
      "| Product Category Unique Values | Electronics, Other   |\n",
      "+--------------------------------+----------------------+\n",
      "\n",
      "=== Transformation Summary: transformed_incremental.csv ===\n",
      "+--------------------------------+-----------------------------+\n",
      "| File                           | transformed_incremental.csv |\n",
      "+--------------------------------+-----------------------------+\n",
      "| Rows                           | 10                          |\n",
      "+--------------------------------+-----------------------------+\n",
      "| Duplicate Rows                 | 0                           |\n",
      "+--------------------------------+-----------------------------+\n",
      "| Any Missing Values             | False                       |\n",
      "+--------------------------------+-----------------------------+\n",
      "| Product Category Unique Values | Electronics                 |\n",
      "+--------------------------------+-----------------------------+\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jpcha\\AppData\\Local\\Temp\\ipykernel_12428\\4047370646.py:80: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[:, col] = df[col].fillna(pd.Timestamp('1970-01-01'))\n",
      "C:\\Users\\jpcha\\AppData\\Local\\Temp\\ipykernel_12428\\4047370646.py:80: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df.loc[:, col] = df[col].fillna(pd.Timestamp('1970-01-01'))\n"
     ]
    }
   ],
   "source": [
    "# --- ETL Transform Step ---\n",
    "# Apply at least 4 meaningful transformations to both datasets, including categorization by modifying existing columns\n",
    "\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "# Load extracted data\n",
    "raw_df = pd.read_csv('data/raw_data.csv')\n",
    "incremental_df = pd.read_csv('data/incremental_data.csv')\n",
    "\n",
    "# Fix missing values in both dataframes before transformation\n",
    "for df in [raw_df, incremental_df]:\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':  # Object type (string)\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "            mean_val = df[col].mean()\n",
    "            if pd.notnull(mean_val):\n",
    "                mean_val = float(f'{mean_val:.1g}')\n",
    "            df[col] = df[col].fillna(mean_val)  # Fill numeric with rounded mean (1 sig fig)\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df[col] = df[col].fillna(pd.Timestamp('1970-01-01'))\n",
    "        else:\n",
    "            df[col] = df[col].fillna('Unknown')\n",
    "\n",
    "def reorder_columns(df):\n",
    "    cols = list(df.columns)\n",
    "    # Move 'product_category' after 'product' if present\n",
    "    if 'product_category' in cols and 'product' in cols:\n",
    "        cols.remove('product_category')\n",
    "        prod_idx = cols.index('product')\n",
    "        cols.insert(prod_idx + 1, 'product_category')\n",
    "    # Move 'total_price' after 'unit_price'\n",
    "    if 'total_price' in cols and 'unit_price' in cols:\n",
    "        cols.remove('total_price')\n",
    "        unit_idx = cols.index('unit_price')\n",
    "        cols.insert(unit_idx + 1, 'total_price')\n",
    "    return df[cols]\n",
    "\n",
    "def categorize_product(product):\n",
    "    # Example categorization logic, adjust as needed for your data\n",
    "    if isinstance(product, str):\n",
    "        p = product.lower()\n",
    "        if any(x in p for x in ['shirt', 'pants', 'dress', 'clothes', 'apparel']):\n",
    "            return 'Apparel'\n",
    "        elif any(x in p for x in ['phone', 'laptop', 'tablet', 'electronics']):\n",
    "            return 'Electronics'\n",
    "        elif any(x in p for x in ['book', 'magazine', 'novel']):\n",
    "            return 'Books'\n",
    "        elif any(x in p for x in ['food', 'snack', 'beverage', 'drink']):\n",
    "            return 'Food & Beverage'\n",
    "        else:\n",
    "            return 'Other'\n",
    "    return 'Other'\n",
    "\n",
    "def transform(df):\n",
    "    # 1. Remove duplicate rows\n",
    "    df = df.drop_duplicates().copy()\n",
    "    \n",
    "    # 2. Handle missing values for all columns\n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'O':  # Object type (string)\n",
    "            df.loc[:, col] = df[col].fillna('Unknown')\n",
    "        elif pd.api.types.is_numeric_dtype(df[col]):\n",
    "            mean_val = df[col].mean()\n",
    "            if pd.notnull(mean_val):\n",
    "                mean_val = float(f'{mean_val:.1g}')\n",
    "            df.loc[:, col] = df[col].fillna(mean_val)  # Fill numeric with rounded mean (1 sig fig)\n",
    "        elif pd.api.types.is_datetime64_any_dtype(df[col]):\n",
    "            df.loc[:, col] = df[col].fillna(pd.Timestamp('1970-01-01'))\n",
    "        else:\n",
    "            df.loc[:, col] = df[col].fillna('Unknown')\n",
    "    \n",
    "    # 3. Convert date columns to datetime (example: 'Date' or 'date')\n",
    "    for col in df.columns:\n",
    "        if 'date' in col.lower():\n",
    "            df.loc[:, col] = pd.to_datetime(df[col], errors='coerce')\n",
    "            df.loc[:, col] = df[col].fillna(pd.Timestamp('1970-01-01'))\n",
    "    \n",
    "    # 4. Categorize 'product' into broader groups (add 'product_category' column)\n",
    "    if 'product' in df.columns:\n",
    "        df.loc[:, 'product_category'] = df['product'].apply(categorize_product)\n",
    "    \n",
    "    # 5. Remove time from 'order_date' if present\n",
    "    if 'order_date' in df.columns:\n",
    "        df.loc[:, 'order_date'] = pd.to_datetime(df['order_date'], errors='coerce').dt.strftime('%Y-%m-%d')\n",
    "    \n",
    "    # 6. Enrichment: Add total_price = quantity * unit_price\n",
    "    if 'quantity' in df.columns and 'unit_price' in df.columns:\n",
    "        df.loc[:, 'total_price'] = df['quantity'] * df['unit_price']\n",
    "    \n",
    "    # 7. Ensure quantity, unit_price, and total_price are whole numbers (integers)\n",
    "    for col in ['quantity', 'unit_price', 'total_price']:\n",
    "        if col in df.columns:\n",
    "            df.loc[:, col] = pd.to_numeric(df[col], errors='coerce').fillna(0).astype(int)\n",
    "    \n",
    "    # 8. Reorder columns for output and CSV\n",
    "    df = reorder_columns(df)\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Apply transformations\n",
    "transformed_full = transform(raw_df)\n",
    "transformed_incremental = transform(incremental_df)\n",
    "\n",
    "# Save transformed files\n",
    "os.makedirs('transformed', exist_ok=True)\n",
    "transformed_full.to_csv('transformed/transformed_full.csv', index=False)\n",
    "transformed_incremental.to_csv('transformed/transformed_incremental.csv', index=False)\n",
    "print(\"\\nTransformed files saved to 'transformed/transformed_full.csv' and 'transformed/transformed_incremental.csv'\")\n",
    "\n",
    "# Display only the head of the final outputs, with 'product_category' after 'product' and 'total_price' after 'unit_price'\n",
    "def print_head_with_category(df, name):\n",
    "    df = reorder_columns(df)\n",
    "    print(f\"\\n=== Head of {name} ===\")\n",
    "    print(tabulate(df.head(), headers='keys', tablefmt='grid'))\n",
    "\n",
    "print_head_with_category(transformed_full, 'transformed_full.csv')\n",
    "print_head_with_category(transformed_incremental, 'transformed_incremental.csv')\n",
    "\n",
    "# Show summary of transformations for verification\n",
    "def transformation_summary(df, name):\n",
    "    summary = [\n",
    "        ['File', name],\n",
    "        ['Rows', len(df)],\n",
    "        ['Duplicate Rows', df.duplicated().sum()],\n",
    "        ['Any Missing Values', df.isnull().any().any()],\n",
    "    ]\n",
    "    if 'product_category' in df.columns:\n",
    "        summary.append(['Product Category Unique Values', ', '.join(df['product_category'].unique().astype(str))])\n",
    "    print(tabulate(summary, tablefmt='grid'))\n",
    "\n",
    "print(\"\\n=== Transformation Summary: transformed_full.csv ===\")\n",
    "transformation_summary(transformed_full, 'transformed_full.csv')\n",
    "print(\"\\n=== Transformation Summary: transformed_incremental.csv ===\")\n",
    "transformation_summary(transformed_incremental, 'transformed_incremental.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
